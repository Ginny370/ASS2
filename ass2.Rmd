---
title: "ASS2"
author: "JingyiPei_u7457361"
date: "2022-10-28"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

GitHub link: https://github.com/Ginny370/ASS2

```{r}
library(tidyverse)
library(metafor)
library(orchaRd)
library(flextable)
```

# Statistical Analysis and Interpretation

## 1. Correct analysis of Clark et al. (2020) data (i.e., OA_activitydat_20190302_BIOL3207.csv) to generate the summary statistics (means, SD, N) for each of the fish species’ average activity for each treatment.

```{r}
# load data
d_OA <- read.csv("./data/OA_activitydat_20190302_BIOL3207.csv")
# move NA and generate the summary statistic
data <-d_OA %>% group_by(species, treatment) %>%
              summarise(mean = mean(activity, na.rm = TRUE),
                        sd = sd(activity, na.rm = TRUE),
                        n = length(unique(animal_id)), .groups = "drop") %>%
              rename(Species = "species")
```

## 2. Through coding, merge the summary statistics generated from 1) with the metadata (i.e., clark_paper_data.csv) from Clark et al. (2020).

```{r}
# load clark paper data
c_meta <- read.csv("./data/clark_paper_data.csv")
sum1 <- cbind(c_meta, data)
```

## 3. Through coding, correctly merge the combined summary statistics and metadata from Clark et al. (2020) (output from 1 & 2) into the larger meta-analysis dataset (i.e., ocean_meta_data.csv).

```{r}
# load ocean_meta_data
ocean <- read.csv("./data/ocean_meta_data.csv")

# combine data (output from 1&2)
sum2 <- pivot_wider(sum1, names_from = treatment,
                     names_glue = "{treatment}_{.value}",
                     values_from = c("mean", "sd", "n"))
# because here is a little different between Clark data and ocean data, we should edit something
 ## Do some renaming of colnames
sum3 <- sum2 %>% rename("oa.mean" = CO2_mean,
                            "oa.sd" = CO2_sd,
                            "oa.n" = CO2_n,
                            "ctrl.mean" = control_mean,
                            "ctrl.sd" = control_sd,
                            "ctrl.n" = control_n)

# Reorder col names based on names in meta_data_full
sum3 <- sum3[names(ocean)]

# Check columns are in same order
colnames(ocean) == colnames(sum3)

# Bind the two dataframes
final_meta <- rbind(ocean, sum3)
```

## 4. Correctly calculate the log response ratio (lnRR) effect size for every row of the dataframe using metafor’s escalc() function.

```{r}
lnRR <- metafor::escalc(measure = "ROM", m1i = ctrl.mean, m2i = oa.mean, sd1i = ctrl.sd, sd2i = oa.sd, n1i = ctrl.n, n2i = oa.n, data = final_meta,
    var.names = c("lnRR", "V_lnRR"))
```

## 5. Correct meta-analytic model fitted to the data that controls for the sampling variance of lnRR. The model should include a random effect of study and observation. Use metafor’s rma.mv() function.

```{r}
final <- lnRR %>% mutate(residual = 1:n())
MLMA <- metafor::rma.mv(yi=lnRR,V=V_lnRR, random = list(~1|Study, ~1|residual), method = "REML", test = "t", dfs = "contain", data=final)
MLMA
```

## 6. Written paragraph of the findings and what they mean which is supported with a figure. The paragraph should include:
### Correct presentation and interpretation of overall meta-analytic mean and measures of uncertainty around the mean estimate (e.g., 95% confidence intervals).
```{r}
predict(MLMA, transf = "transf.ztor")
```
We can extract the 95% confidence intervals which range from -0.350 to 0.098. In other words, 95% of the time we would expect the true mean to fall between lnRR values of -0.350 to 0.098. It indicates that if we were to repeat the experiment many times, 95% of the confidence intervals constructed would contain the true meta-analytic mean between -0.350 to 0.098.

### Measures of heterogeneity in effect size estimates across studies (i.e., I2 and/or prediction intervals - see predict() function in metafor)
```{r}
## Calculate I2
i2_vals <- orchaRd::i2_ml(MLMA)

## Make a pretty table. First, lets clean up the names of the different I2
## estimates. Lets remove I2_. It's a string, so, we can use some regular
## expressions to fix that. `gsub` is pretty useful. You put a pattern in and
## tell it what you would like to replace the text with. In this case, just
## blank will do! Then, we'll make the first letter of what is left
## capitalised.
i2 <- tibble(type = firstup(gsub("I2_", "", names(i2_vals))), I2 = i2_vals)


# Make a pretty table. 
flextable(i2) %>%
    align(part = "header", align = "center") %>%
    compose(part = "header", j = 1, value = as_paragraph(as_b("Type"))) %>%
    compose(part = "header", j = 2, value = as_paragraph(as_b("I"), as_b(as_sup("2")),
        as_b("(%)")))
```


### Forest plot showing the mean estimate, 95% confidence interval, and prediction interval with clearly labelled axes, number of samples and studies plotted on figure



```{r}
# Make an orchard plot using the model object
orchaRd::orchard_plot(MLMA, mod = 1, group = "Life.stage", data = final,xlab = "log response ratio (lnRR) effect", angle = 45)
```

## 7.  plot for visually assessing the possibility of publication bias.

## 8. Time-lag plot assessing how effect sizes may or may not have changed through time.

## 9. Formal meta-regression model that includes year as a moderator (fixed effect) to test for time-lag bias

## 10. Formal meta-regression model that includes inverse sampling variance (i.e., 1vlnRR) to test for file-drawer biases

## 11. A written paragraph that discusses the potential for publication bias based on the meta-regression results. What type of publication bias, if any, appears to be present in the data? If publication bias is present, what does it mean and what might be contributing to such bias?

# 12. Identify any studies contributing to publication bias. How do your updated meta-analysis results compare with a meta-analysis by Clement et. al. (2022)? Are there any concerns about these studies? If so, describe using references to existing papers what concerns have been raised?
